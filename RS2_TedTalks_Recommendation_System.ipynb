{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src= \"https://cdn.mos.cms.futurecdn.net/Xfwn3VUhmDttDsxXmEqbw6-1200-80.jpg\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TED Talks Öneri Sistemi (Deep Learning)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ## Proje Hakkında\n",
    "  ### Problemin Tanımı:\n",
    "  Bu proje, kullanıcıların ilgi duydukları TED konuşmalarına benzer içerikleri keşfetmelerini sağlayan bir Derin Öğrenme (Deep\n",
    "  Learning) Tabanlı Öneri Sistemi geliştirmeyi amaçlar. Geleneksel yöntemler (TF-IDF gibi) kelime sıklıklarına odaklanırken, bu proje\n",
    "  kelimelerin anlamsal ilişkilerini analiz eder.\n",
    "\n",
    "  ### Kullanılan Yöntemler:\n",
    "   * Sentence-BERT (SBERT): all-MiniLM-L6-v2 adlı önceden eğitilmiş Transformer modeli kullanılarak, her bir konuşma metni 384\n",
    "     boyutlu yoğun bir vektöre (embedding) dönüştürülür. Bu sayede \"iklim değişikliği\" ile \"küresel ısınma\" gibi farklı kelimelerle\n",
    "     ifade edilen ama aynı anlama gelen kavramlar birbirine yakın vektörler olarak temsil edilir.\n",
    "   * Cosine Similarity: Oluşturulan anlamsal vektörler arasındaki açısal benzerlik hesaplanarak, içerik açısından en yakın konuşmalar\n",
    "     belirlenir.\n",
    "\n",
    "  ### Hedef Çıktı:\n",
    "  Kullanıcı bir konuşma seçtiğinde, sistem veritabanındaki binlerce konuşma arasından anlamsal olarak en yakın 10 konuşmayı önerir.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Erhan\\anaconda3\\Lib\\site-packages\\keras\\src\\export\\tf2onnx_lib.py:8: FutureWarning: In the future `np.object` will be defined as the corresponding NumPy scalar.\n",
      "  if not hasattr(np, \"object\"):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Erhan\\anaconda3\\Lib\\site-packages\\tf_keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import joblib\n",
    "import os\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Veri Yükleme (Data Loading)\n",
    "  Gerekli kütüphaneler (sentence_transformers, pandas, sklearn) yüklenir. ted_main.csv (meta veriler) ve transcripts.csv (metin\n",
    "  dökümleri) dosyaları okunur ve url sütunu üzerinden birleştirilir. Analiz için sadece başlık, konuşmacı ve metin sütunları seçilir.\n",
    "  Eksik metin verileri temizlenir."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2467, 4)\n"
     ]
    }
   ],
   "source": [
    "df_main = pd.read_csv('../data/ted_main.csv')\n",
    "df_transcripts = pd.read_csv('../data/transcripts.csv')\n",
    "df = pd.merge(df_main, df_transcripts, on='url')\n",
    "df = df[['title', 'transcript', 'url', 'main_speaker']]\n",
    "df['transcript'] = df['transcript'].fillna('')\n",
    "print(df.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2467 entries, 0 to 2466\n",
      "Data columns (total 4 columns):\n",
      " #   Column        Non-Null Count  Dtype \n",
      "---  ------        --------------  ----- \n",
      " 0   title         2467 non-null   object\n",
      " 1   transcript    2467 non-null   object\n",
      " 2   url           2467 non-null   object\n",
      " 3   main_speaker  2467 non-null   object\n",
      "dtypes: object(4)\n",
      "memory usage: 77.2+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>transcript</th>\n",
       "      <th>url</th>\n",
       "      <th>main_speaker</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Do schools kill creativity?</td>\n",
       "      <td>Good morning. How are you?(Laughter)It's been ...</td>\n",
       "      <td>https://www.ted.com/talks/ken_robinson_says_sc...</td>\n",
       "      <td>Ken Robinson</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Averting the climate crisis</td>\n",
       "      <td>Thank you so much, Chris. And it's truly a gre...</td>\n",
       "      <td>https://www.ted.com/talks/al_gore_on_averting_...</td>\n",
       "      <td>Al Gore</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Simplicity sells</td>\n",
       "      <td>(Music: \"The Sound of Silence,\" Simon &amp; Garfun...</td>\n",
       "      <td>https://www.ted.com/talks/david_pogue_says_sim...</td>\n",
       "      <td>David Pogue</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Greening the ghetto</td>\n",
       "      <td>If you're here today — and I'm very happy that...</td>\n",
       "      <td>https://www.ted.com/talks/majora_carter_s_tale...</td>\n",
       "      <td>Majora Carter</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The best stats you've ever seen</td>\n",
       "      <td>About 10 years ago, I took on the task to teac...</td>\n",
       "      <td>https://www.ted.com/talks/hans_rosling_shows_t...</td>\n",
       "      <td>Hans Rosling</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             title  \\\n",
       "0      Do schools kill creativity?   \n",
       "1      Averting the climate crisis   \n",
       "2                 Simplicity sells   \n",
       "3              Greening the ghetto   \n",
       "4  The best stats you've ever seen   \n",
       "\n",
       "                                          transcript  \\\n",
       "0  Good morning. How are you?(Laughter)It's been ...   \n",
       "1  Thank you so much, Chris. And it's truly a gre...   \n",
       "2  (Music: \"The Sound of Silence,\" Simon & Garfun...   \n",
       "3  If you're here today — and I'm very happy that...   \n",
       "4  About 10 years ago, I took on the task to teac...   \n",
       "\n",
       "                                                 url   main_speaker  \n",
       "0  https://www.ted.com/talks/ken_robinson_says_sc...   Ken Robinson  \n",
       "1  https://www.ted.com/talks/al_gore_on_averting_...        Al Gore  \n",
       "2  https://www.ted.com/talks/david_pogue_says_sim...    David Pogue  \n",
       "3  https://www.ted.com/talks/majora_carter_s_tale...  Majora Carter  \n",
       "4  https://www.ted.com/talks/hans_rosling_shows_t...   Hans Rosling  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deep Learning Modelinin Yüklenmesi\n",
    "  Hugging Face kütüphanesinden all-MiniLM-L6-v2 modeli indirilir. Bu model, cümleleri ve paragrafları hızlı ve etkili bir şekilde\n",
    "  vektörleştirmek için optimize edilmiştir. Boyutu küçük olmasına rağmen (yaklaşık 80MB), performansı oldukça yüksektir.\n",
    "\n",
    "###  Metinlerin Vektörleştirilmesi (Encoding)\n",
    "  Veri setindeki tüm TED konuşma metinleri (transcripts), yüklenen Transformer modelinden geçirilir. Model, her bir konuşma için 384\n",
    "  sayıdan oluşan benzersiz bir Embedding Vektörü üretir. Bu vektörler, konuşmanın \"anlamsal parmak izi\" gibidir. İşlem sonunda\n",
    "  elimizde (Konuşma Sayısı, 384) boyutunda bir matris oluşur.\n",
    "\n",
    "### Benzerlik Matrisi (Cosine Similarity)\n",
    "  Elde edilen embedding matrisi kullanılarak, her konuşmanın diğer tüm konuşmalarla olan benzerlik skoru hesaplanır. Sonuçta (N, N)\n",
    "  boyutunda kare bir matris elde edilir. Bu matrisin [i, j] hücresi, i. ve j. konuşmaların ne kadar benzer olduğunu (0 ile 1\n",
    "  arasında) gösterir.\n",
    "\n",
    "### Öneri Testi\n",
    "  Sistemin çalışıp çalışmadığını test etmek için rastgele bir konuşma seçilir. Hesaplanan benzerlik matrisinden bu konuşmaya ait\n",
    "  satır çekilir, skorlar büyükten küçüğe sıralanır ve en yüksek skora sahip ilk 10 konuşma (kendisi hariç) listelenir."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "36911f17ce924dc1bdf09fa798e93abf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "modules.json:   0%|          | 0.00/349 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Erhan\\anaconda3\\Lib\\site-packages\\huggingface_hub\\file_download.py:143: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\Erhan\\.cache\\huggingface\\hub\\models--sentence-transformers--all-MiniLM-L6-v2. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ffd416cb7bf54f08bf489dc2e9d59def",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config_sentence_transformers.json:   0%|          | 0.00/116 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "29323530d395463da93e17b750996828",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6f9148c68fce4915a17cf5285ff6cfab",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "sentence_bert_config.json:   0%|          | 0.00/53.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "50afbf72707e4a7c919d3a1b63fdb2de",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/612 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d32c705780bd41aba5285f7dd64b6e3f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/90.9M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a6279a0b21f94dd78f171e9a6f6b4506",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/350 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "87b2f18dc04342ab9a3d45ef60178dd5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8f2eae2b2a21497fabee73f95bf215bf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "346f5ab1631b4c9ab9b1f7c6363bda00",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/112 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e5bc7fa65973408fb805f6e88010ebac",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/190 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "733ef0037c5044908506714c2e19a9fe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/78 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "embeddings = model.encode(df['transcript'].tolist(), show_progress_bar=True)\n",
    "cosine_sim_dl = cosine_similarity(embeddings, embeddings)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modelleri Kaydetme\n",
    "  Oluşturulan Benzerlik Matrisi (cosine_sim_dl.pkl), Veri Seti (ted_data.pkl) ve İndeks Sözlüğü (indices.pkl) diske kaydedilir. Bu\n",
    "  dosyalar, modelin tekrar tekrar eğitilmesine gerek kalmadan Streamlit uygulamasında hızlıca kullanılmasını sağlar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved.\n"
     ]
    }
   ],
   "source": [
    "indices = pd.Series(df.index, index=df['title']).drop_duplicates()\n",
    "if not os.path.exists('../models'): os.makedirs('../models')\n",
    "joblib.dump(cosine_sim_dl, '../models/cosine_sim_dl.pkl')\n",
    "joblib.dump(df[['title', 'main_speaker', 'url']], '../models/ted_data.pkl')\n",
    "joblib.dump(indices, '../models/indices.pkl')\n",
    "print('Saved.')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
